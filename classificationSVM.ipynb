{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import glob\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"./ECSE415_Project/MIO-TCD-Classification/train/*\"\n",
    "#mypath = \"ClassificationDataset/train/*\"\n",
    "files = glob.glob(mypath)\n",
    "X =[]\n",
    "Y =[]\n",
    "for i, file in enumerate (files):\n",
    "    print(i, file, \"\\n\")\n",
    "    filelist=[]\n",
    "    j =0\n",
    "    for f in listdir(file):\n",
    "        if(not isfile(join(file,f))):\n",
    "            continue\n",
    "        X.append(cv2.resize(cv2.imread(str(file) + \"/\" + str(f)),(80,80)))\n",
    "        Y.append(i)\n",
    "        j+=1\n",
    "        #number of images to take in each set\n",
    "        if (j>=5000):\n",
    "            break\n",
    "#show the first image just to see\n",
    "plt.imshow(cv2.cvtColor(X[0], cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Input Image\"), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute list of hogs for each image (using helper function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heper function to compute the hog features from a list of images\n",
    "def computeHoGfeatures(img_list):\n",
    "    #compute HoG features of size (32,32,8) with blocknorm of 4x4\n",
    "    cell_size = (4, 4)  # h x w in pixels\n",
    "    block_size = (4, 4)  # h x w in cells\n",
    "    nbins = 8  # number of orientation bins\n",
    "    \n",
    "    #create array to contain the hog features (flattened and not)\n",
    "    hog_features = [None]*len(img_list)\n",
    "    for i in range(len(img_list)):\n",
    "        # create HoG Object\n",
    "        # winSize is the size of the image cropped to an multiple of the cell size\n",
    "        hog = cv2.HOGDescriptor(_winSize=(img_list[i].shape[1] // cell_size[1] * cell_size[1],\n",
    "                                          img_list[i].shape[0] // cell_size[0] * cell_size[0]),\n",
    "                                _blockSize=(block_size[1] * cell_size[1],\n",
    "                                            block_size[0] * cell_size[0]),\n",
    "                                _blockStride=(cell_size[1], cell_size[0]),\n",
    "                                _cellSize=(cell_size[1], cell_size[0]),\n",
    "                                _nbins=nbins)\n",
    "\n",
    "        n_cells = (img_list[i].shape[0] // cell_size[0], img_list[i].shape[1] // cell_size[1])\n",
    "\n",
    "        # Compute HoG features\n",
    "        hog_feats = hog.compute(img_list[i])\\\n",
    "                       .reshape(n_cells[1] - block_size[1] + 1,\n",
    "                                n_cells[0] - block_size[0] + 1,\n",
    "                                block_size[0], block_size[1], nbins) \\\n",
    "                       .transpose((1, 0, 2, 3, 4))  # index blocks by rows first\n",
    "\n",
    "        # computation for BlockNorm\n",
    "        #gradients = np.full((n_cells[0], n_cells[1], 9), 0, dtype=float)\n",
    "        gradients = np.full((n_cells[0], n_cells[1], nbins), 0, dtype=float)\n",
    "        cell_count = np.full((n_cells[0], n_cells[1], 1), 0, dtype=int)\n",
    "        for off_y in range(block_size[0]):\n",
    "            for off_x in range(block_size[1]):\n",
    "                gradients[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                          off_x:n_cells[1] - block_size[1] + off_x + 1] += \\\n",
    "                    hog_feats[:, :, off_y, off_x, :]\n",
    "                cell_count[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                           off_x:n_cells[1] - block_size[1] + off_x + 1] += 1\n",
    "        # Average gradients\n",
    "        gradients /= cell_count\n",
    "        gradients_flattened = gradients.flatten()\n",
    "        hog_features[i] = gradients_flattened\n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hog_features = computeHoGfeatures(X)\n",
    "print(len(hog_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best hyper parameters on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectParameters(vectors, labels):\n",
    "    #combination of l1 and squared_hinge / hinge is not supported\n",
    "    svm_param = ParameterGrid([{'random_state':[0],'loss':['hinge','squared_hinge'],'C':[0.01,.1, 1.0, 5.0]}])\n",
    "    classifier = svm.LinearSVC\n",
    "    best_mean_acc = 0\n",
    "    for param in svm_param:\n",
    "        print(\"With params :\", param)\n",
    "        clf = classifier(**param)\n",
    "        scores = cross_val_score(clf, vectors,labels)\n",
    "        print(\"The scores accross validations are:\", scores)\n",
    "        mean_acc = scores.mean()\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (mean_acc, scores.std() * 2))\n",
    "        if(mean_acc > best_mean_acc):\n",
    "            best_mean_acc = mean_acc\n",
    "            best_clf = clf\n",
    "            best_params = param\n",
    "        print(\"Mean Accuracy achieved : \", mean_acc) \n",
    "    print(\"\\nFinal best params: \", best_params, \"\\nBest mean accuracy score on cross validation: \", best_mean_acc, \"\\n\")\n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "start_time = time.time()\n",
    "best_clf = selectParameters(hog_features, Y)\n",
    "print(\"Computation time: \", \"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(best_clf,hog_features, Y, cv=10)\n",
    "print(\"Average Accuracy across validations: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "recall = cross_val_score(best_clf, hog_features, Y, cv=10,scoring='recall_micro')\n",
    "print(\"Average Recall across validations: \", np.mean(recall))\n",
    "precision = cross_val_score(best_clf, hog_features, Y, cv=10, scoring='precision_micro')\n",
    "print(\"Average Precision across validations: \", np.mean(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred =  best_clf.predict(hog_features)\n",
    "conf = confusion_matrix(Y, pred)\n",
    "plt.figure()\n",
    "plt.imshow(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(best_clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
