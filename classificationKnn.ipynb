{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# extract images from label directories into training and test sets\n",
    "def extract_label_images(path,label,training_images,training_labels,train_value,test_images,test_labels,test_value):\n",
    "    new_path = path + \"/\" +label\n",
    "    train_count = 0\n",
    "    test_count = 0\n",
    "    \n",
    "    if label == \"background\":\n",
    "        train_value = 50000\n",
    "    \n",
    "    ## resize images to 128x128 grayscale \n",
    "    for file in os.listdir(new_path):\n",
    "    # grab only 10 images from label directory for testing purposes \n",
    "        if (train_count < train_value):\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(new_path+ \"/\" +file)), cv2.COLOR_BGR2GRAY)\n",
    "            #print(img.shape)\n",
    "            img = cv2.resize(img,(64,64))\n",
    "            training_images.append(img)\n",
    "            training_labels.append(label)\n",
    "            train_count = train_count + 1 \n",
    "            \n",
    "        elif (test_count < test_value):\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(new_path+ \"/\" +file)), cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img,(64,64))\n",
    "            test_images.append(img)\n",
    "            test_labels.append(label)\n",
    "            test_count = test_count + 1 \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print(\"FINISH EXTRACTING LABEL : \", label)\n",
    "                \n",
    "    return training_images,test_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractLabels(path):\n",
    "    label_list = []\n",
    "    for file in os.listdir(path):\n",
    "        label_list.append(\"\"+file)\n",
    "    return label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHogFeatures(images):\n",
    "    cell_size = (4, 4)  # h x w in pixels\n",
    "    block_size = (4, 4)  # h x w in cells\n",
    "    nbins = 8  # number of orientation bins\n",
    "    \n",
    "    hog = cv2.HOGDescriptor(_winSize=(images[0].shape[1] // cell_size[1] * cell_size[1],\n",
    "                                          images[0].shape[0] // cell_size[0] * cell_size[0]),\n",
    "                                _blockSize=(block_size[1] * cell_size[1],\n",
    "                                            block_size[0] * cell_size[0]),\n",
    "                                _blockStride=(cell_size[1], cell_size[0]),\n",
    "                                _cellSize=(cell_size[1], cell_size[0]),\n",
    "                                _nbins=nbins)\n",
    "    \n",
    "    n_cells = (images[0].shape[0] // cell_size[0], images[0].shape[1] // cell_size[1])\n",
    "    \n",
    "    listOfHogFeatures = []\n",
    "    for img in images:\n",
    "        # create HoG Object\n",
    "        # winSize is the size of the image cropped to an multiple of the cell size\n",
    "        \n",
    "\n",
    "        # Compute HoG features\n",
    "        hog_feats = hog.compute(img)\\\n",
    "                       .reshape(n_cells[1] - block_size[1] + 1,\n",
    "                                n_cells[0] - block_size[0] + 1,\n",
    "                                block_size[0], block_size[1], nbins) \\\n",
    "                       .transpose((1, 0, 2, 3, 4))  # index blocks by rows first\n",
    "\n",
    "        # hog_feats now contains the gradient amplitudes for each direction,for each cell of its group for each group.\n",
    "        # Indexing is by rows then columns.\n",
    "        # computation for BlockNorm\n",
    "        gradients = np.full((n_cells[0], n_cells[1], 8), 0, dtype=float)\n",
    "        cell_count = np.full((n_cells[0], n_cells[1], 1), 0, dtype=int)\n",
    "\n",
    "        for off_y in range(block_size[0]):\n",
    "            for off_x in range(block_size[1]):\n",
    "                gradients[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                          off_x:n_cells[1] - block_size[1] + off_x + 1] += \\\n",
    "                    hog_feats[:, :, off_y, off_x, :]\n",
    "                cell_count[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                           off_x:n_cells[1] - block_size[1] + off_x + 1] += 1\n",
    "\n",
    "        # Average gradients\n",
    "        gradients /= cell_count\n",
    "        # turn gradient 32,32,8 3D array to 1D for training \n",
    "        reshaped_gradients = gradients.ravel()\n",
    "        listOfHogFeatures.append(reshaped_gradients)\n",
    "        \n",
    "    return listOfHogFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH EXTRACTING LABEL :  articulated_truck\n",
      "FINISH EXTRACTING LABEL :  background\n",
      "FINISH EXTRACTING LABEL :  bicycle\n",
      "FINISH EXTRACTING LABEL :  bus\n",
      "FINISH EXTRACTING LABEL :  car\n",
      "FINISH EXTRACTING LABEL :  motorcycle\n",
      "FINISH EXTRACTING LABEL :  non-motorized_vehicle\n",
      "FINISH EXTRACTING LABEL :  pedestrian\n",
      "FINISH EXTRACTING LABEL :  pickup_truck\n",
      "FINISH EXTRACTING LABEL :  single_unit_truck\n",
      "FINISH EXTRACTING LABEL :  work_van\n",
      "91017\n",
      "91017\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "training_set_path= r\"./MIO-TCD-Classification/train\"\n",
    "labels = extractLabels(training_set_path)\n",
    "train_images = []\n",
    "train_labels = []\n",
    "train_value = 5000\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "test_value = 1\n",
    "\n",
    "## Extracting 128x128 gray scale images from each label directory\n",
    "\n",
    "for label in labels:\n",
    "    extract_label_images(training_set_path, label, train_images, train_labels, train_value, test_images, test_labels, test_value)\n",
    "\n",
    "print(len(train_images))\n",
    "print(len(train_labels))\n",
    "print(len(test_images))\n",
    "print(len(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract hog features of each images of labels \n",
    "training_img_features = getHogFeatures(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=4, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3, n_jobs = 4)\n",
    "model.fit(training_img_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42315, 2048)\n",
      "(4702, 2048)\n",
      "(42315,)\n",
      "(4702,)\n"
     ]
    }
   ],
   "source": [
    "training_img_features = np.array(training_img_features)\n",
    "train_labels = np.array(train_labels)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(training_img_features, train_labels, train_size=0.9, test_size=0.1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "# prediction_data = getHogFeatures(test_images)\n",
    "# result = model.predict(prediction_data)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE ACCURACY SCORE :  0.780720240778394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy = cross_val_score(model, X_train, Y_train, cv=10, n_jobs = 5, scoring='accuracy')\n",
    "print(\"AVERAGE ACCURACY SCORE : \",np.mean(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = cross_val_score(model, X_train, Y_train, cv=10, n_jobs = 5, scoring='recall_micro')\n",
    "print(\"AVERAGE RECALL SCORE : \", np.mean(recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = cross_val_score(model, X_train, Y_train, cv=10, n_jobs = 5, scoring='precision_micro')\n",
    "print(\"AVERAGE PRECISION SCORE : \", np.mean(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23be9215048>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "results = model.predict(X_train)\n",
    "conf = confusion_matrix(results, Y_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename.pk1']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SAVING MODEL\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, 'filename.pk1')\n",
    "\n",
    "# # load back the pickled model at a later time\n",
    "# clf = joblib.load('filename.pk1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
