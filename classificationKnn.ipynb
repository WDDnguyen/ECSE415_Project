{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# extract images from label directories into training and test sets\n",
    "def extract_label_images(path,label,training_images,training_labels,train_value,test_images,test_labels,test_value):\n",
    "    new_path = path + \"/\" +label\n",
    "    train_count = 0\n",
    "    test_count = 0\n",
    "    \n",
    "    ## resize images to 128x128 grayscale \n",
    "    for file in os.listdir(new_path):\n",
    "    # grab only 10 images from label directory for testing purposes \n",
    "        if (train_count < train_value):\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(new_path+ \"/\" +file)), cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img,(128,128))\n",
    "            training_images.append(img)\n",
    "            training_labels.append(label)\n",
    "            train_count = train_count + 1 \n",
    "            \n",
    "        elif (test_count < test_value):\n",
    "            img = cv2.cvtColor(cv2.imread(os.path.join(new_path+ \"/\" +file)), cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img,(128,128))\n",
    "            test_images.append(img)\n",
    "            test_labels.append(label)\n",
    "            test_count = test_count + 1 \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    print(\"FINISH EXTRACTING LABEL : \", label)\n",
    "                \n",
    "    return training_images,test_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractLabels(path):\n",
    "    label_list = []\n",
    "    for file in os.listdir(path):\n",
    "        label_list.append(\"\"+file)\n",
    "    return label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHogFeatures(images):\n",
    "    cell_size = (4, 4)  # h x w in pixels\n",
    "    block_size = (4, 4)  # h x w in cells\n",
    "    nbins = 8  # number of orientation bins\n",
    "    \n",
    "    hog = cv2.HOGDescriptor(_winSize=(images[0].shape[1] // cell_size[1] * cell_size[1],\n",
    "                                          images[0].shape[0] // cell_size[0] * cell_size[0]),\n",
    "                                _blockSize=(block_size[1] * cell_size[1],\n",
    "                                            block_size[0] * cell_size[0]),\n",
    "                                _blockStride=(cell_size[1], cell_size[0]),\n",
    "                                _cellSize=(cell_size[1], cell_size[0]),\n",
    "                                _nbins=nbins)\n",
    "    \n",
    "    n_cells = (images[0].shape[0] // cell_size[0], images[0].shape[1] // cell_size[1])\n",
    "    \n",
    "    listOfHogFeatures = []\n",
    "    for img in images:\n",
    "        # create HoG Object\n",
    "        # winSize is the size of the image cropped to an multiple of the cell size\n",
    "        \n",
    "\n",
    "        # Compute HoG features\n",
    "        hog_feats = hog.compute(img)\\\n",
    "                       .reshape(n_cells[1] - block_size[1] + 1,\n",
    "                                n_cells[0] - block_size[0] + 1,\n",
    "                                block_size[0], block_size[1], nbins) \\\n",
    "                       .transpose((1, 0, 2, 3, 4))  # index blocks by rows first\n",
    "\n",
    "        # hog_feats now contains the gradient amplitudes for each direction,for each cell of its group for each group.\n",
    "        # Indexing is by rows then columns.\n",
    "        # computation for BlockNorm\n",
    "        gradients = np.full((n_cells[0], n_cells[1], 8), 0, dtype=float)\n",
    "        cell_count = np.full((n_cells[0], n_cells[1], 1), 0, dtype=int)\n",
    "\n",
    "        for off_y in range(block_size[0]):\n",
    "            for off_x in range(block_size[1]):\n",
    "                gradients[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                          off_x:n_cells[1] - block_size[1] + off_x + 1] += \\\n",
    "                    hog_feats[:, :, off_y, off_x, :]\n",
    "                cell_count[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                           off_x:n_cells[1] - block_size[1] + off_x + 1] += 1\n",
    "\n",
    "        # Average gradients\n",
    "        gradients /= cell_count\n",
    "        # turn gradient 32,32,8 3D array to 1D for training \n",
    "        reshaped_gradients = gradients.ravel()\n",
    "        listOfHogFeatures.append(reshaped_gradients)\n",
    "        \n",
    "    return listOfHogFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH EXTRACTING LABEL :  articulated_truck\n",
      "FINISH EXTRACTING LABEL :  background\n",
      "FINISH EXTRACTING LABEL :  bicycle\n",
      "FINISH EXTRACTING LABEL :  bus\n",
      "FINISH EXTRACTING LABEL :  car\n",
      "FINISH EXTRACTING LABEL :  motorcycle\n",
      "FINISH EXTRACTING LABEL :  non-motorized_vehicle\n",
      "FINISH EXTRACTING LABEL :  pedestrian\n",
      "FINISH EXTRACTING LABEL :  pickup_truck\n",
      "FINISH EXTRACTING LABEL :  single_unit_truck\n",
      "FINISH EXTRACTING LABEL :  work_van\n",
      "16500\n",
      "16500\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "training_set_path= r\"./MIO-TCD-Classification/train\"\n",
    "labels = extractLabels(training_set_path)\n",
    "train_images = []\n",
    "train_labels = []\n",
    "train_value = 1500\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "test_value = 1\n",
    "\n",
    "## Extracting 128x128 gray scale images from each label directory\n",
    "\n",
    "for label in labels:\n",
    "    extract_label_images(training_set_path, label, train_images, train_labels, train_value, test_images, test_labels, test_value)\n",
    "\n",
    "print(len(train_images))\n",
    "print(len(train_labels))\n",
    "print(len(test_images))\n",
    "print(len(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract hog features of each images of labels \n",
    "training_img_features = getHogFeatures(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "#model.fit(training_img_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_data = getHogFeatures(test_images)\n",
    "# result = model.predict(prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(result)\n",
    "#print(test_labels)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "training_img_features = shuffle(training_img_features, random_state=0)\n",
    "train_labels = shuffle(train_labels, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifierAccuracy(predictions, answers):\n",
    "    total_predictions = len(predictions)\n",
    "    correct_predictions = 0\n",
    "    for p, a in zip(predictions, answers):\n",
    "        if (p == a):\n",
    "            correct_predictions = correct_predictions + 1 \n",
    "            \n",
    "    print(\"CORRECT predictions : \", correct_predictions)\n",
    "    print(\"TOTAL PREDICTIONS : \", total_predictions)\n",
    "    print(\"ACCURACY \", (correct_predictions/total_predictions))\n",
    "  \n",
    "    return (correct_predictions/total_predictions)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT predictions :  12567\n",
      "TOTAL PREDICTIONS :  14850\n",
      "ACCURACY  0.8462626262626263\n",
      "CORRECT predictions :  1187\n",
      "TOTAL PREDICTIONS :  1650\n",
      "ACCURACY  0.7193939393939394\n",
      "CORRECT predictions :  12568\n",
      "TOTAL PREDICTIONS :  14850\n",
      "ACCURACY  0.8463299663299664\n",
      "CORRECT predictions :  1203\n",
      "TOTAL PREDICTIONS :  1650\n",
      "ACCURACY  0.7290909090909091\n",
      "CORRECT predictions :  12553\n",
      "TOTAL PREDICTIONS :  14850\n",
      "ACCURACY  0.8453198653198654\n",
      "CORRECT predictions :  1180\n",
      "TOTAL PREDICTIONS :  1650\n",
      "ACCURACY  0.7151515151515152\n",
      "CORRECT predictions :  12566\n",
      "TOTAL PREDICTIONS :  14850\n",
      "ACCURACY  0.8461952861952862\n",
      "CORRECT predictions :  1183\n",
      "TOTAL PREDICTIONS :  1650\n",
      "ACCURACY  0.7169696969696969\n",
      "CORRECT predictions :  12581\n",
      "TOTAL PREDICTIONS :  14850\n",
      "ACCURACY  0.8472053872053872\n",
      "CORRECT predictions :  1186\n",
      "TOTAL PREDICTIONS :  1650\n",
      "ACCURACY  0.7187878787878788\n",
      "CORRECT predictions :  12520\n",
      "TOTAL PREDICTIONS :  14850\n",
      "ACCURACY  0.8430976430976431\n",
      "CORRECT predictions :  1196\n",
      "TOTAL PREDICTIONS :  1650\n",
      "ACCURACY  0.7248484848484849\n",
      "CORRECT predictions :  12528\n",
      "TOTAL PREDICTIONS :  14850\n",
      "ACCURACY  0.8436363636363636\n",
      "CORRECT predictions :  1220\n",
      "TOTAL PREDICTIONS :  1650\n",
      "ACCURACY  0.7393939393939394\n",
      "CORRECT predictions :  12525\n",
      "TOTAL PREDICTIONS :  14850\n",
      "ACCURACY  0.8434343434343434\n",
      "CORRECT predictions :  1203\n",
      "TOTAL PREDICTIONS :  1650\n",
      "ACCURACY  0.7290909090909091\n",
      "CORRECT predictions :  12533\n",
      "TOTAL PREDICTIONS :  14850\n",
      "ACCURACY  0.8439730639730639\n",
      "CORRECT predictions :  1208\n",
      "TOTAL PREDICTIONS :  1650\n",
      "ACCURACY  0.7321212121212122\n",
      "CORRECT predictions :  12516\n",
      "TOTAL PREDICTIONS :  14850\n",
      "ACCURACY  0.8428282828282828\n",
      "CORRECT predictions :  1200\n",
      "TOTAL PREDICTIONS :  1650\n",
      "ACCURACY  0.7272727272727273\n",
      "[0.8462626262626263, 0.8463299663299664, 0.8453198653198654, 0.8461952861952862, 0.8472053872053872, 0.8430976430976431, 0.8436363636363636, 0.8434343434343434, 0.8439730639730639, 0.8428282828282828]\n",
      "[0.7193939393939394, 0.7290909090909091, 0.7151515151515152, 0.7169696969696969, 0.7187878787878788, 0.7248484848484849, 0.7393939393939394, 0.7290909090909091, 0.7321212121212122, 0.7272727272727273]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# The .split() method returns indices to the dataset\n",
    "kf_splitter = KFold(n_splits=10)\n",
    "## In each loop, train our regressor and save the MSE\n",
    "\n",
    "train_label_prediction_accuracy = []\n",
    "valid_label_prediction_accuracy = []\n",
    "## NOTE: We can use cross_val_score instead of this loop\n",
    "\n",
    "training_img_features = np.array(training_img_features)\n",
    "train_labels = np.array(train_labels)\n",
    "#print(len(train_labels))\n",
    "\n",
    "for train_index, valid_index in kf_splitter.split(training_img_features):\n",
    "\n",
    "    train_set = training_img_features[train_index, :]\n",
    "    t_label = train_labels[train_index]\n",
    "    \n",
    "    # Get our validation data in this fold\n",
    "    valid_set = training_img_features[valid_index, :]\n",
    "    v_label = train_labels[valid_index]\n",
    "    \n",
    "    # Train KNN Classfier\n",
    "    model.fit(train_set, t_label)\n",
    "    \n",
    "    # Get our prediction for training, validation:\n",
    "    prediction_train = model.predict(train_set)\n",
    "    prediction_valid = model.predict(valid_set)\n",
    "    \n",
    "    train_label_prediction_accuracy.append(classifierAccuracy(prediction_train, t_label))\n",
    "    valid_label_prediction_accuracy.append(classifierAccuracy(prediction_valid, v_label))\n",
    "\n",
    "# Print the mse\n",
    "print(train_label_prediction_accuracy)\n",
    "print(valid_label_prediction_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f58f437860>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf = confusion_matrix( v_label, prediction_valid)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVING MODEL\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, 'filename.pk1')\n",
    "\n",
    "# # load back the pickled model at a later time\n",
    "# clf = joblib.load('filename.pk1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
